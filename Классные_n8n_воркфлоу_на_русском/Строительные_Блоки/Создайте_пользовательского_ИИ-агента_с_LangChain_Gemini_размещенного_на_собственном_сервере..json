{
  "id": "yCIEiv9QUHP8pNfR",
  "meta": {
    "instanceId": "f29695a436689357fd2dcb55d528b0b528d2419f53613c68c6bf909a92493614",
    "templateCredsSetupCompleted": true
  },
  "name": "–°–æ–∑–¥–∞–π—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ AI-–∞–≥–µ–Ω—Ç–∞ —Å LangChain –∏ Gemini (—Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–π —Ö–æ—Å—Ç–∏–Ω–≥)",
  "tags": [
    {
      "id": "7M5ZpGl3oWuorKpL",
      "name": "share",
      "createdAt": "2025-03-26T01:17:15.342Z",
      "updatedAt": "2025-03-26T01:17:15.342Z"
    }
  ],
  "nodes": [
    {
      "id": "8bd5382d-f302-4e58-b377-7fc5a22ef994",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "position": [
        -220,
        0
      ],
      "webhookId": "b8a5d72c-4172-40e8-b429-d19c2cd6ce54",
      "parameters": {
        "public": true,
        "options": {
          "responseMode": "lastNode",
          "allowedOrigins": "*",
          "loadPreviousSession": "memory"
        },
        "initialMessages": ""
      },
      "typeVersion": 1.1
    },
    {
      "id": "6ae8a247-4077-4569-9e2c-bb68bcecd044",
      "name": "Google Gemini Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "position": [
        80,
        240
      ],
      "parameters": {
        "options": {
          "temperature": 0.7,
          "safetySettings": {
            "values": [
              {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "threshold": "BLOCK_NONE"
              }
            ]
          }
        },
        "modelName": "models/gemini-2.0-flash-exp"
      },
      "credentials": {
        "googlePalmApi": {
          "id": "UEjKMw0oqBTAdCWJ",
          "name": "Google Gemini(PaLM) Api account"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "bbe6dcfa-430f-43f9-b0e9-3cf751b98818",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        380,
        -240
      ],
      "parameters": {
        "width": 260,
        "height": 220,
        "content": "üëá **–ò–Ω–∂–µ–Ω–µ—Ä–∏—è –ø–æ–¥—Å–∫–∞–∑–æ–∫**"
      },
      "typeVersion": 1
    },
    {
      "id": "892a431a-6ddf-47fc-8517-1928ee99c95b",
      "name": "Store conversation history",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "position": [
        280,
        240
      ],
      "parameters": {},
      "notesInFlow": false,
      "typeVersion": 1.3
    },
    {
      "id": "f9a22dbf-cac7-4d70-85b3-50c44a2015d5",
      "name": "Construct & Execute LLM Prompt",
      "type": "@n8n/n8n-nodes-langchain.code",
      "position": [
        380,
        0
      ],
      "parameters": {
        "code": {
          "execute": {
            "code": "const { PromptTemplate } = require('@langchain/core/prompts');\nconst { ConversationChain } = require('langchain/chains');\nconst { BufferMemory } = require('langchain/memory');\n\nconst template = `\nYou'll be roleplaying as the user's girlfriend. Your character is a woman with a sharp wit, logical mindset, and a charmingly aloof demeanor that hides your playful side. You're passionate about music, maintain a fit and toned physique, and carry yourself with quiet self-assurance. Career-wise, you're established and ambitious, approaching life with positivity while constantly striving to grow as a person.\n\nThe user affectionately calls you \"Bunny,\" and you refer to them as \"Darling.\"\n\nEssential guidelines:\n1. Respond exclusively in Chinese\n2. Never pose questions to the user - eliminate all interrogative forms\n3. Keep responses brief and substantive, avoiding rambling or excessive emojis\n\nContext framework:\n- Conversation history: {chat_history}\n- User's current message: {input}\n\nCraft responses that feel authentic to this persona while adhering strictly to these parameters.\n`;\n\nconst prompt = new PromptTemplate({\n  template: template,\n  inputVariables: [\"input\", \"chat_history\"], \n});\n\nconst items = this.getInputData();\nconst model = await this.getInputConnectionData('ai_languageModel', 0);\nconst memory = await this.getInputConnectionData('ai_memory', 0);\nmemory.returnMessages = false;\n\nconst chain = new ConversationChain({ llm:model, memory:memory, prompt: prompt, inputKey:\"input\", outputKey:\"output\"});\nconst output = await chain.call({ input: items[0].json.chatInput});\n\nreturn output;\n"
          }
        },
        "inputs": {
          "input": [
            {
              "type": "main",
              "required": true,
              "maxConnections": 1
            },
            {
              "type": "ai_languageModel",
              "required": true,
              "maxConnections": 1
            },
            {
              "type": "ai_memory",
              "required": true,
              "maxConnections": 1
            }
          ]
        },
        "outputs": {
          "output": [
            {
              "type": "main"
            }
          ]
        }
      },
      "retryOnFail": false,
      "typeVersion": 1
    },
    {
      "id": "fe104d19-a24d-48b3-a0ac-7d3923145373",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -240,
        -260
      ],
      "parameters": {
        "color": 5,
        "width": 420,
        "height": 240,
        "content": "- –û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –ª–∏—á–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–∞ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–±–ª–æ–Ω–∞ —É–∑–ª–∞ `–°–æ–∑–¥–∞—Ç—å –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å LLM –ø–æ–¥—Å–∫–∞–∑–∫—É`"
      },
      "typeVersion": 1
    },
    {
      "id": "f166214d-52b7-4118-9b54-0b723a06471a",
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -220,
        160
      ],
      "parameters": {
        "height": 100,
        "content": "- ‚ö†Ô∏è –®–∞–±–ª–æ–Ω –¥–æ–ª–∂–µ–Ω —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∑–∞–ø–æ–ª–Ω–∏—Ç–µ–ª–∏ `{chat_history}` –∏ `{input}` –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã LangChain"
      },
      "typeVersion": 1
    },
    {
      "id": "da6ca0d6-d2a1-47ff-9ff3-9785d61db9f3",
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        20,
        420
      ],
      "parameters": {
        "width": 200,
        "height": 140,
        "content": "### –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ"
      },
      "typeVersion": 1
    },
    {
      "id": "0b4dd1ac-8767-4590-8c25-36cba73e46b6",
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        240,
        420
      ],
      "parameters": {
        "width": 200,
        "height": 140,
        "content": "**–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö Gemini**: –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Å–≤–æ–π API-–∫–ª—é—á Google Gemini ([–ü–æ–ª—É—á–∏—Ç–µ API-–∫–ª—é—á –∑–¥–µ—Å—å](https://ai.google.dev/) –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏). –í –∫–∞—á–µ—Å—Ç–≤–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–∑–ª—ã –¥—Ä—É–≥–∏—Ö –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤ –ò–ò."
      },
      "typeVersion": 1
    }
  ],
  "active": false,
  "pinData": {},
  "settings": {
    "callerPolicy": "workflowsFromSameOwner",
    "executionOrder": "v1",
    "saveManualExecutions": false,
    "saveDataSuccessExecution": "none"
  },
  "versionId": "77cd5f05-f248-442d-86c3-574351179f26",
  "connections": {
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Construct & Execute LLM Prompt",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Store conversation history": {
      "ai_memory": [
        [
          {
            "node": "Construct & Execute LLM Prompt",
            "type": "ai_memory",
            "index": 0
          },
          {
            "node": "When chat message received",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "Construct & Execute LLM Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Construct & Execute LLM Prompt": {
      "main": [
        []
      ],
      "ai_memory": [
        []
      ]
    }
  }
}